{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "\n",
    "## Homework 7:  ANNs and Model interpretability \n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2019**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader and Chris Tanner<br/>\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL FOR FORMAT\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- **This is an individual homework. No group collaboration.**\n",
    "- To submit your assignment, follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and are aiming to teach. And if a problem specifies a particular library, you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### cs109default ### \n",
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint \n",
    "\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "### cs109default ### \n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)  # You should see a 2.0.0 here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"exercise\"> <b> Question 1: Construct a feed forward neural network [25 pts]</b> </div>\n",
    "\n",
    "In this part of the homework, you are to construct three feed-forward neural networks. Each neural network will consist of an input layer, a hidden layer, and an output layer. The three different networks only differ in their number of nodes used for their hidden layer, which we specify for each specific question below. All networks' hidden layers use the sigmoid as the activation function, along with a linear output node. \n",
    "\n",
    "**You should code the equations from scratch.**\n",
    "\n",
    "You are given three datasets containing $(x,y)$ points where $y=f(x)$:\n",
    "\n",
    "- In the first dataset, $f(x)$ is a **single step** function (data in`data/step_df.csv`), \n",
    "- In the second dataset, $f(x)$ is a **one hump** function (data in `data/one_hump_df.csv`),\n",
    "- In the third dataset, $f(x)$ is a **two equal humps** function (data in `data/two_hump_df.csv`).\n",
    "\n",
    " \n",
    "\n",
    "**1.1** Read the files into variables name `step_df`, `one_hump_df`, and `two_hump_df`.\n",
    "Perform a forward pass using a network with one hidden layer with **one** node. The input to the network is the $x$ `step_df.x`.  Adjust the weights manually until the predicted outputs matches as closely as possible to the true $y$s (`step_df.y`) and plot the output from the network; in the same plot, show the true $y$ values. \n",
    "\n",
    "**1.2** Do the same for the **one hump** function data, this time using a hidden layer consisting of **two** nodes.\n",
    "\n",
    "**1.3** Do the same for the **two humps** function data, but this time increase the number of hidden nodes to **four**.  \n",
    "\n",
    "**1.4** Choose the appropriate loss function and calculate and report the loss from all three cases. Derive the gradient of **the output layer's weights** for all three cases (step, one hump, and two humps). Use the weights for the hidden layers you found in the previous question and perform gradient descent on the weights of this layer (output layer). What are the optimized weight value and loss you obtained? \n",
    "\n",
    "__NOTE: Only perform gradient descent for the output layer's weights (the ones that connect the hidden layer to the output layer)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.1** Read the files into variables name `step_df`, `one_hump_df`, and `two_hump_df`.\n",
    "Perform a forward pass using a network with one hidden layer with **one** node. The input to the network is the $x$ `step_df.x`.  Adjust the weights manually until the predicted outputs matches as closely as possible to the true $y$s (`step_df.y`) and plot the output from the network; in the same plot, show the true $y$ values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "test": "test_sigmoid"
   },
   "outputs": [],
   "source": [
    "### cs109Test(test_sigmoid) ### \n",
    "def sigmoid(x: float) -> float :\n",
    "    \"\"\"The sigmoid function \n",
    "    \"\"\"    \n",
    "    # your code here \n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "test": "test_1.1a"
   },
   "outputs": [],
   "source": [
    "### cs109Test(test_1.1a) ### \n",
    "## read data \n",
    "# your code here\n",
    "step_df=pd.read_csv('step_df.csv')\n",
    "one_hump_df=pd.read_csv('one_hump_df.csv')\n",
    "two_hump_df=pd.read_csv('two_hump_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "test": "test_forwardpass"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_forwardpass) ###\n",
    "# Forward pass\n",
    "\n",
    "def forward_step(X_in: np.ndarray, WL_0: np.ndarray, \n",
    "                 WL_1: np.ndarray, y_out: np.ndarray) -> (float, float) :\n",
    "    \n",
    "    \"\"\"\n",
    "    This implements forward step:\n",
    "        z = X_in . WL_0 #Input layer . Weights\n",
    "        h = sigmoid(z)  #hidden \n",
    "        y = h . WL_1    #Output layer \n",
    "        (Add intercepts as appropriate)\n",
    "    \n",
    "    Args (3 different scenarios 1.1, 1.2 and 1.3): \n",
    "        X_in: Input array\n",
    "              1.1 - Array shape (100,1)\n",
    "              1.2 - Array shape (100,1)\n",
    "              1.3 - Array Shape (100,1)\n",
    "              \n",
    "        WL_0: Input array [Weights for Layer 0]\n",
    "              1.1 - Array shape (2,1)\n",
    "              1.2 - Array shape (2,2)\n",
    "              1.3 - Array shape (2,4)\n",
    "              \n",
    "        WL_1: Input Array [Weights for Layer 1]\n",
    "              1.1 - Array shape (2,1) \n",
    "              1.2 - Array shape (3,1) \n",
    "              1.3 - Array shape (5,1)\n",
    "\n",
    "        y_out: Input Array\n",
    "              1.1 - Array shape (100,1)\n",
    "              1.2 - Array shape (100,1)\n",
    "              1.3 - Array shape (100,1)\n",
    "              \n",
    "    Returns:\n",
    "              1.1 - Output = (100, 1), hidden = (100, 2)\n",
    "              1.2 - Output = (100, 1), hidden = (100, 3)\n",
    "              1.3 - Output = (100, 1), hidden = (100, 5)\n",
    "              (hidden will be utilized for 1.4)    \n",
    "    \"\"\"\n",
    " \n",
    "    # your code here \n",
    "    n=len(X_in)\n",
    "    X_array=X_in.values.reshape(n,1)\n",
    "    ones = np.ones((n,1))\n",
    "    X_addconst = np.append(X_array, ones, axis=1)\n",
    "    \n",
    "    z = np.dot(X_addconst,WL_0)\n",
    "    h = sigmoid(z) \n",
    "    hidden = np.append(h, ones, axis=1)\n",
    "    \n",
    "    y = np.dot(hidden,WL_1)\n",
    "    output = y\n",
    "\n",
    "    \n",
    "    # end of your code here\n",
    "    \n",
    "    \n",
    "    return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(y_true,y_pre):\n",
    "    return np.mean((y_true-y_pre)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "test": "test1.1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003375175156889486"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cs109Test(test1.1b) ###\n",
    "# ONE STEP - one node in hidden layer \n",
    "step_df_sort=step_df.sort_values('x')\n",
    "y_pre = forward_step(step_df_sort.x, np.array([[10],[-20]]), \n",
    "                 np.array([[1],[.001]]), step_df_sort.y)[0]\n",
    "loss_mse(step_df_sort.y.values.reshape(100,1),y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x152cad8ca20>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the prediction vs true\n",
    "# your code here\n",
    "plt.plot(step_df_sort.x,step_df_sort.y,'o',label='True data')\n",
    "plt.plot(step_df_sort.x,y_pre,label='Fitted data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### 1.1 Check that you have the requested variables\n",
    "for var in ['sigmoid', 'forward_step', 'step_df' , 'one_hump_df' , 'two_hump_df']:\n",
    "    assert var in globals(), f\"Variable '{var}' does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.2** Do the same for the **one hump** function data, this time using a hidden layer consisting of **two** nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "deletable": false,
    "test": "test1.2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1944918780813493"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cs109Test(test1.2) ###\n",
    "# ONE HUMP  - two nodes in hidden layer\n",
    "# your code here\n",
    "one_hump_df_sort=one_hump_df.sort_values('x')\n",
    "\n",
    "y_pre = forward_step(one_hump_df_sort.x, np.array([[-9,-41],[18,250]]), \n",
    "                 np.array([[-1],[1],[0]]), one_hump_df_sort.y)[0]\n",
    "loss_mse(step_df_sort.y.values.reshape(100,1),y_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x152d4009128>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(one_hump_df_sort.x,one_hump_df_sort.y,'o',label='True data')\n",
    "plt.plot(one_hump_df_sort.x,y_pre,label='Fitted data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3** Do the same for the **two humps** function data, but this time increase the number of hidden nodes to **four**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "deletable": false,
    "test": "test1.3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x152d9267518>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### cs109Test(test1.3) ###\n",
    "# TWO HUMPS  - four nodes in hidden layer \n",
    "# your code here\n",
    "two_hump_df_sort=two_hump_df.sort_values('x')\n",
    "y_pre = forward_step(one_hump_df_sort.x, np.array([[6,-50,0.5,10],[3,2,50,-10]]), \n",
    "                 np.array([[1],[0],[0],[0],[0]]), one_hump_df_sort.y)[0]\n",
    "loss_mse(step_df_sort.y.values.reshape(100,1),y_pre)\n",
    "\n",
    "plt.plot(two_hump_df_sort.x,two_hump_df_sort.y,'o',label='True data')\n",
    "plt.plot(two_hump_df_sort.x,y_pre,label='Fitted data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.4** Choose the appropriate loss function and calculate and report the loss from all three cases. Derive the gradient of **the output layer's weights** for all three cases (step, one hump, and two humps). Use the weights for the hidden layers you found in the previous question and perform gradient descent on the weights of this layer (output layer). What are the optimized weight value and loss you obtained?\n",
    "\n",
    "__NOTE: Only perform gradient descent for the output layer's weights (the ones that connect the hidden layer to the output layer)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "test": "testLostFunctions"
   },
   "outputs": [],
   "source": [
    "### cs109Test (testLostFunctions) ###\n",
    "\n",
    "# Loss function \n",
    "def L(y_pred, y):   \n",
    "    \"\"\"\n",
    "    This function returns the appropriate loss given the predictions and actual values\n",
    "    Inputs: \n",
    "        y_pred: A vector with the predicted y values \n",
    "        y:      A vector with the true y values \n",
    "    Output:\n",
    "        loss:   A scalar for the loss\"\"\"\n",
    "    # your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "test": "test_der_L_WL1"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_der_L_WL1) ###\n",
    "\n",
    "    \n",
    "# derivative with respect to W1\n",
    "def der_L_WL1(z, y_pred, y):\n",
    "    \"\"\"\n",
    "    This function calculates the derivatives with respect to output weights\n",
    "    Inputs: \n",
    "        y_pred: A vector with the predicted y values \n",
    "        y:      A vector with the true y values \n",
    "        z:      A vector with the values of the output layer \n",
    "    Output:\n",
    "        ders:   A vector of partial derivatives \n",
    "    \"\"\"\n",
    "    # your code here \n",
    "    # end of your code here\n",
    "    return ders # returns vector of partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "test": "test_GradientDescent"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_GradientDescent) ###\n",
    "\n",
    "# gradient descent \n",
    "def gradient_descent(steps, lr, WL0, WL1, X, y):\n",
    "    \"\"\"\n",
    "    This function performs Gradient Descent\n",
    "    Inputs: \n",
    "        steps: Number of steps\n",
    "        lr: Learning Rate\n",
    "        WL0: Layer 0 weights\n",
    "        WL1: Layer 1 weights - Initital value\n",
    "        X: X\n",
    "        y: y\n",
    "     Outputs:\n",
    "        z1:  A vector with the final values of y (after steps steps)\n",
    "        WL1_n: The final values of WL1 (after steps steps)\n",
    "        errors: list of errors\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # your code here \n",
    "    # end of your code here\n",
    "    return z1, WL1_n, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### a) step function NN (a hidden layer with a single node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# SINGLE STEP\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### b) one hump function NN (a hidden layer with two nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# ONE HUMP\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### c) two hump function NN (a hidden layer with 4 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# TWO HUMPS\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<hr style='height:2pt'>\n",
    "<div class='theme'> Neural Networks part B</div> \n",
    "\n",
    "Neural networks are, of course, a large and complex topic that cannot be covered in a single homework. Here, we'll focus on the key idea of ANNs: they are able to learn a mapping from example input data (of fixed size) to example output data (of fixed size). We'll also partially explore what patterns the neural network learns and how well neural networks generalize.\n",
    "\n",
    "In this question we'll see if neural networks can learn a limited version of the [Fourier Transform.](https://en.wikipedia.org/wiki/Fourier_transform) (The Fourier Transform takes in values from some function and returns a set of sine and cosine functions which, when added together, approximate the original function.)\n",
    "\n",
    "In symbols: $ \\cal{F(s)} = \\int_{-\\infty}^\\infty f(x)e^{- i xs}dx$. In words, the value of the transformed function at some point, $s$, is the value of an integral which measures, in some sense, how much the original $f(x)$ looks like a wave with a period of $s$. As an example, with $f(x) = 4cos(x) + sin(2x)$,  $\\cal{F}(s)$ is 0 everywhere except at -2, -1, 1, and 2, mapping to the waves of period 1 and 1/2. The values at these points are linked to the magnitude of the waves, and their phases (roughly: sin waves versus cosine waves).\n",
    "\n",
    "The only thing about the Fourier transform that matters for this p-set is this: a function goes in, and a re-written form in terms of sine and cosine comes out.\n",
    "\n",
    "In our specific problem, we'll train a network to map from 1000 sample values from a function (equally spaced along 0 to 2$\\pi$) to the four features of the sine and cosine waves that make up that function. Thus, the network is attempting to learn a mapping from a 1000-entry vector down to a 4-entry vector. Our `X_train` dataset's shape is $N x 1000$ and our `y_train` is $N x 4.$\n",
    "\n",
    "Questions 2.1 and 2.2 will get you used to the format of the data. \n",
    "\n",
    "We'll use 6 data files in this question:\n",
    "- `sinewaves_X_train.npy` and `sinewaves_y_train.npy`: a (10,000 x 1,000) and (10,000 x 4) training dataset. Examples were generated by randomly selecting a,b,c,d in the interval [0,1] and building the curve $a\\sin(b\\,x) + c\\cos(d\\,x)$\n",
    "- `sinewaves_X_test.npy` and `sinewaves_y_test.npy`: a (2,000 x 1,000) and (2,000 x 4) test dataset, generated in the same way as the training data\n",
    "- `sinewaves_X_extended_test` and `sinewaves_y_extended_test`: a (9 x 1,000) and (9 x 4) test dataset, testing whether the network can generalize beyond the training data (e.g. to negative values of $a$)\n",
    "\n",
    "**These datasets are read in to their respective variables for you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'> <b> Question 2 [25pts] </b> </div>\n",
    "    \n",
    "**2.1** Plot the first row of the `X_train` training data and visually verify that it is a sinusoidal curve.\n",
    "\n",
    "**2.2** The first row of the `y_train` data is $[0.024, 0.533, 0.018, 0.558]$. Visually or numerically verify that the first row of X_train is 1000 equally-spaced samples in $[0,10\\pi]$ from the function $f(x) = 0.024\\sin(0.533\\,x) + 0.018\\cos(0.558\\,x)$. This pattern (y_train is the true parameters of the curve in X_train) will always hold.\n",
    "\n",
    "**2.3** Use `tf.keras` to build a fully-connected neural network:\n",
    "\n",
    "**a:** Use `tf.keras.models.Sequential` and `tf.keras.layers.Dense` to build the fully-connected neural network. You can choose any number of layers and any number of nodes in each layer. \n",
    "\n",
    "**b:** Compile your model via the line `model.compile(loss='mean_absolute_error', optimizer='adam')` and display the `.summary()`. Explain why the first layer in your network has the indicated number of parameters.\n",
    "\n",
    "**c:** Fit your model to the data for $50$ epochs using a batch size of $32$ and a validation split of $0.2$. You can train for longer if you wish -- the fit tends to improve over time.\n",
    "\n",
    "**2.4** Use the `plot_predictions` function to plot the model's predictions on `X_test` to the true values in `y_test` (by default, it will only plot the first few rows). Report the model's overall loss on the test set. Comment on how well the model performs on this unseen data. Do you think it has accurately learned how to map from sample data to the coefficients that generated the data?\n",
    "\n",
    "**2.5** Examine the model's performance on the 9 train/test pairs in the `extended_test` variables. Which examples does the model do well on, and which examples does it struggle with?\n",
    "\n",
    "**2.6** Is there something that stands out about the difficult examples, especially with respect to the data the model was trained on? Did the model learn the mapping we had in mind? Would you say the model is overfit, underfit, or neither?\n",
    "\n",
    "**Hint**:\n",
    "- The Tensorflow 2.0 [`tf.keras` (here)](https://www.tensorflow.org/guide/keras) documentation and examples of a Sequential model are a good place to start.\n",
    "- A strong model can achieve validation error of around 0.03 on this data and 0.02 is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### cs109default ### \n",
    "def plot_predictions(model, test_x, test_y, count=None):\n",
    "    # Model - a tf.keras model that takes in (n,1000) training data and predicts (n,4) output data\n",
    "    # test_x - a (n,1000) input dataset\n",
    "    # test_y - a (n,4) output dataset\n",
    "    # This function will plot the sine curves in the training data and those implied by the model's predictions.\n",
    "    # It will also print the predicted and actual output values.\n",
    "    \n",
    "    #helper function that takes the n by 4 output and reverse-engineers \n",
    "    #the sine curves that output would create\n",
    "    def y2x(y_data):\n",
    "        #extract parameters\n",
    "        a=y_data[:,0].reshape(-1,1)\n",
    "        b=y_data[:,1].reshape(-1,1)\n",
    "        c=y_data[:,2].reshape(-1,1)\n",
    "        d=y_data[:,3].reshape(-1,1)\n",
    "\n",
    "        #build the matching training data\n",
    "        x_points = np.linspace(0,10*np.pi,1000)\n",
    "        x_data = a*np.sin(np.outer(b,x_points)) + c*np.cos(np.outer(d,x_points))\n",
    "        return x_data\n",
    "    \n",
    "    #if <20 examples, plot all. If more, just plot 5\n",
    "    if count==None:\n",
    "        if test_x.shape[0]>20:\n",
    "            count=5\n",
    "        else:\n",
    "            count=test_x.shape[0]\n",
    "    \n",
    "    #build predictions\n",
    "    predicted = model.predict(test_x)\n",
    "    implied_x = y2x(predicted)\n",
    "    for i in range(count):\n",
    "        plt.plot(test_x[i,:],label='true')\n",
    "        plt.plot(implied_x[i,:],label='predicted')\n",
    "        plt.legend()\n",
    "        plt.ylim(-2.1,2.1)\n",
    "        plt.xlabel(\"x value\")\n",
    "        plt.xlabel(\"y value\")\n",
    "        plt.title(\"Curves using the Neural Network's Approximate Fourier Transform\")\n",
    "        plt.show()\n",
    "        print(\"true:\", test_y[i,:])\n",
    "        print(\"predicted:\", predicted[i,:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/sinewaves_X_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-481-ea507c7dae43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### cs109default ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/sinewaves_X_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/sinewaves_y_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/sinewaves_X_test.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfcs109a\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/sinewaves_X_train.npy'"
     ]
    }
   ],
   "source": [
    "### cs109default ### \n",
    "X_train = np.load('data/sinewaves_X_train.npy')\n",
    "y_train = np.load('data/sinewaves_y_train.npy')\n",
    "\n",
    "X_test = np.load('data/sinewaves_X_test.npy')\n",
    "y_test = np.load('data/sinewaves_y_test.npy')\n",
    "\n",
    "X_extended_test = np.load('data/sinewaves_X_extended_test.npy')\n",
    "y_extended_test = np.load('data/sinewaves_y_extended_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Answers:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.1** Plot the first row of the `X_train` training data and visually verify that it is a sinusoidal curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.2** The first row of the `y_train` data is $[0.024, 0.533, 0.018, 0.558]$. Visually or numerically verify that the first row of X_train is 1000 equally-spaced samples in $[0,10\\pi]$ from the function $f(x) = 0.024\\sin(0.533\\,x) + 0.018\\cos(0.558\\,x)$. This pattern (y_train is the true parameters of the curve in X_train) will always hold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.3** Use `tf.keras` to build a fully-connected neural network:\n",
    "\n",
    "**a:** Use `tf.keras.models.Sequential` and `tf.keras.layers.Dense` to build the fully-connected neural network. You can choose any number of layers and any number of nodes in each layer.\n",
    "\n",
    "**b:** Compile your model via the line `model.compile(loss='mean_absolute_error', optimizer='adam')` and display the `.summary()`. Explain why the first layer in your network has the indicated number of parameters.\n",
    "\n",
    "**c:** Fit your model to the data for $50$ epochs using a batch size of $32$ and a validation split of $0.2$. You can train for longer if you wish -- the fit tends to improve over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# build the fully-connected neural network\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Compile your model \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Fit your model \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.4** Use the `plot_predictions` function to plot the model's predictions on `X_test` to the true values in `y_test` (by default, it will only plot the first few rows). Report the model's overall loss on the test set. Comment on how well the model performs on this unseen data. Do you think it has accurately learned how to map from sample data to the coefficients that generated the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# model's overall loss\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.5",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.5** Examine the model's performance on the 9 train/test pairs in the `extended_test` variables. Which examples does the model do well on, and which examples does it struggle with?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.6",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.6** Is there something that stands out about the difficult examples, especially with respect to the data the model was trained on? Did the model learn the mapping we had in mind? Would you say the model is overfit, underfit, or neither?\n",
    "\n",
    "**Hint**:\n",
    "- The Tensorflow 2.0 [`tf.keras` (here)](https://www.tensorflow.org/guide/keras) documentation and examples of a Sequential model are a good place to start.\n",
    "- A strong model can achieve validation error of around 0.03 on this data and 0.02 is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "source": [
    "<hr style='height:2pt'>\n",
    "\n",
    "<div class='theme'> Regularizing Neural Networks </div>\n",
    "\n",
    "In this problem set, we have already explored how ANNs are able to learn a mapping from example input data (of fixed size) to example output data (of fixed size), and how well the neural network can generalize. In this problem, we focus on issues of overfitting and regularization in neural networks.\n",
    "\n",
    "As we have explained in class, ANNs can be prone to overfitting, where they learn specific patterns present in the training data, but the patterns do not generalize to new data.\n",
    "\n",
    "There are several methods used to improve ANN generalization. One approach is to use an architecture just barely wide/deep enough to fit the data. The idea here is that smaller networks are less expressive and thus less able to overfit the data.\n",
    "\n",
    "However, it is difficult to know a priori the correct size of the ANN, and it is computationally costly to hunt for the correct size. Given this, other methodologies are used to prevent overfitting and improve ANNs' generalizability. These methodologies, like other techniques that combat overfitting, fall under the umbrella of regularization.\n",
    "\n",
    "In this problem, you are asked to regularize a network given to you below.\n",
    "    \n",
    "For this problem, we will be working with a modified version of MNIST dataset (MNIST CS109, MNIST: Modified National Institute of Standards and Technology database), which is a large database of handwritten digits and commonly used for training various image processing systems. This dataset consists of 60,000 28x28 grayscale images of the ten digits, along with a test set of 10,000 images. For pedagogical simplicity, we will only use the digits labeled `4` and `9`, and we want to use a total of 1600 samples for training (this includes the data you will use for validation).\n",
    "\n",
    "We have selected the samples for you and the dataset is available at https://www.kaggle.com/c/cs109a. You have to create an account on Kaggle and join competition via https://www.kaggle.com/t/ca16b77c5feb4cbabb0d8cf63d9a7212. This is a limited participation competition. Please do not share link.  \n",
    "\n",
    "`x_train_mnist_cs109.csv` is our training dataset, last column is the target column. Class 0 means sample is handwritten digit 4 and class 1 means sample is handwritten digit 9.  784 columns correspond to 28x28 image size. \n",
    "\n",
    "\n",
    "`x_test_mnist_cs109.csv` has  structure similar to `x_train_mnist_cs109.csv` with no labels. `x_test_mnist_cs109.csv` has 3200  samples. Kaggle leaderboard scores are accuracy scores calculated on this test set.  \n",
    "\n",
    "`sample_submission.csv` is the format that kaggle will accept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "test": "Kaggle_name"
   },
   "source": [
    "\n",
    "<div class='exercise'> <b> Question 3 [25 pts] </b> </div>\n",
    "    \n",
    "**3.1**  Download data from the competition page. You should have three files `x_train_mnist_cs109.csv`, `x_test_mnist_cs109.csv` and `sample_submission.csv`. We will utilize `x_test_mnist_cs109.csv` in 3.3.  Load the data and use the matplotlib function `imshow` to display a handwritten 4 and a handwritten 9.\n",
    "\n",
    "**3.2** **Overfit an ANN:** Build a fully-connected network (FCN) using `tensorflow.keras` and assign it to a variable called `model_overfit`: \n",
    "\n",
    "1. Number of hidden layers: 3\n",
    "2. Nodes per hidden layer: 100,100,100\n",
    "2. Activation function: reLU \n",
    "3. Loss function: binary_crossentropy\n",
    "4. Output unit: Sigmoid \n",
    "5. Optimizer: adam (use the defaults; no other tuning)\n",
    "6. Epochs: no more than 2,000\n",
    "7. Batch size: 128\n",
    "8. Validation size: .3\n",
    "\n",
    "This ANN trained on the dataset you built here will overfit to the training set. Plot the training accuracy and validation accuracy as a function of epochs and explain how you can tell it is overfitting. \n",
    "\n",
    "\n",
    "**3.3** Create an ANN that doesn't overfit and compete on Kaggle.\n",
    "\n",
    "Keep the architecture above as is. In other words, keep the number of layers, number of nodes, activation function,  loss function and output unit the same. You can change the number of epochs (max 2000), batch size, optimizer, and of course, add elements that can help to regularize (e.g., drop out, L2 norm, etc.). You can also do data augmentation. \n",
    "\n",
    "\n",
    "\n",
    "- 3.3.1 Save your model's training accuracy as a variable called `kaggle_train_acc` and make sure it prints in the assert cell provided\n",
    "- 3.3.2 Additionally, display model summary, training and validation accuracy and loss (yes, the training accuracy should be displayed again here).\n",
    "- 3.3.3 Print the difference between training and validation accuracy and loss.\n",
    "- 3.3.4 Plot the training accuracy and validation accuracy as a function of epochs.\n",
    "- 3.3.5 Save the model using `model.save(filename)` and **submit it on canvas along with your notebook**. Code on how to save your model is provided below.\n",
    "- 3.3.6 **Submit your Kaggle name that you have used on the leaderboard. *We can't give you credit without this* . Enter it in the code cell below that starts with ### cs109Test(Kaggle_name) ###.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**RULES:**\n",
    "\n",
    "- **Please do not manually label your submissions.** In other words the labels should be the outcome of your model. \n",
    "\n",
    "- **No CNNs  allowed for this competition. \n",
    "\n",
    "- **No external data are allowed, please only use the x_train_mnist_cs109.csv for training the models.**\n",
    "\n",
    "- Do not create multiple accounts on Kaggle.\n",
    "\n",
    "\n",
    "**Grading:** (all accuracies are in percentages)\n",
    "\n",
    "S1: (Model overfit training accuracy - Model overfit validation accuracy)  => How much are you overfitting 3.2  ?\n",
    "\n",
    "S2: (Good model training accuracy - Good model average on Kaggle)  => How much are you overfitting on kaggle 3.3\n",
    "\n",
    "S3: (min (0, Good model training accuracy - Model overfit training accuracy )) => Your good model accuracy must be higher than model overfit. \n",
    "\n",
    "score = S1 - S2 + S3\n",
    "\n",
    "1. score > 1 : 4pt\n",
    "2. score > 1.5-2.0 : 8pts\n",
    "3. score > 2.0: 12pts\n",
    "4. 3pt extra to the top 10 students\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**3.1**  Download data from the competition page. You should have three files `x_train_mnist_cs109.csv`, `x_test_mnist_cs109.csv` and `sample_submission.csv`. We will utilize `x_test_mnist_cs109.csv` in 3.3.  Load the data and use the matplotlib function `imshow` to display a handwritten 4 and a handwritten 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**3.2** **Overfit an ANN:** Build a fully-connected network (FCN) using `tensorflow.keras` and assign it to a variable called `model_overfit`:\n",
    "\n",
    "1. Number of hidden layers: 3\n",
    "2. Nodes per hidden layer: 100,100,100\n",
    "2. Activation function: reLU\n",
    "3. Loss function: binary_crossentropy\n",
    "4. Output unit: Sigmoid\n",
    "5. Optimizer: adam (use the defaults; no other tuning)\n",
    "6. Epochs: no more than 2,000\n",
    "7. Batch size: 128\n",
    "8. Validation size: .3\n",
    "\n",
    "This ANN trained on the dataset you built here will overfit to the training set. Plot the training accuracy and validation accuracy as a function of epochs and explain how you can tell it is overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.3",
    "deletable": false,
    "editable": false,
    "test": "Kaggle_name"
   },
   "source": [
    "**3.3** Create an ANN that doesn't overfit and compete on Kaggle.\n",
    "\n",
    "Keep the architecture above as is. In other words, keep the number of layers, number of nodes, activation function,  loss function and output unit the same. You can change the number of epochs (max 2000), batch size, optimizer, and of course, add elements that can help to regularize (e.g., drop out, L2 norm, etc.). You can also do data augmentation.\n",
    "\n",
    "\n",
    "- 3.3.1 Save your model's training accuracy as a variable called `kaggle_train_acc` and make sure it prints in the assert cell provided\n",
    "- 3.3.2 Additionally, display model summary, training and validation accuracy and loss (yes, the training accuracy should be displayed again here).\n",
    "- 3.3.3 Print the difference between training and validation accuracy and loss.\n",
    "- 3.3.4 Plot the training accuracy and validation accuracy as a function of epochs.\n",
    "- 3.3.5 Save the model using `model.save(filename)` and **submit it on canvas along with your notebook**. Code on how to save your model is provided below.\n",
    "- 3.3.6 **Submit your Kaggle name that you have used on the leaderboard. *We can't give you credit without this* . Enter it in the code cell below that starts with ### cs109Test(Kaggle_name) ###.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**RULES:**\n",
    "\n",
    "- **Please do not manually label your submissions.** In other words the labels should be the outcome of your model.\n",
    "\n",
    "- **No CNNs  allowed for this competition.\n",
    "\n",
    "- **No external data are allowed, please only use the x_train_mnist_cs109.csv for training the models.**\n",
    "\n",
    "- Do not create multiple accounts on Kaggle.\n",
    "\n",
    "\n",
    "**Grading:** (all accuracies are in percentages)\n",
    "\n",
    "S1: (Model overfit training accuracy - Model overfit validation accuracy)  => How much are you overfitting 3.2  ?\n",
    "\n",
    "S2: (Good model training accuracy - Good model average on Kaggle)  => How much are you overfitting on kaggle 3.3\n",
    "\n",
    "S3: (min (0, Good model training accuracy - Model overfit training accuracy )) => Your good model accuracy must be higher than model overfit.\n",
    "\n",
    "score = S1 - S2 + S3\n",
    "\n",
    "1. score > 1 : 4pt\n",
    "2. score > 1.5-2.0 : 8pts\n",
    "3. score > 2.0: 12pts\n",
    "4. 3pt extra to the top 10 students\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "test": "Kaggle_Train_Acc"
   },
   "outputs": [],
   "source": [
    "### cs109Test(Kaggle_Train_Acc) ###\n",
    "### Print your Kaggle model's train accuracy\n",
    "assert 'kaggle_train_acc' in globals(), f\"Variable 'kaggle_train_acc' does not exist!\"\n",
    "print('Kaggle Train Accuracy: {}'.format(kaggle_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "### cs109default ### \n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### cs109test (Kaggle_name) ###\n",
    "\n",
    "**Enter your Kaggle Leaderboard name as a string in the cell below**\n",
    "\n",
    "**(No credit without the name!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "test": "Kaggle_name"
   },
   "outputs": [],
   "source": [
    "### cs109Test(Kaggle_name) ###\n",
    "# Enter your Kaggle Leaderboard name exactly as it appears\n",
    "# (No name == no credit!)\n",
    "\n",
    "KAGGLE_NAME = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### Check that you entered your Kaggle name!\n",
    "assert 'KAGGLE_NAME' in globals(), f\"Variable 'KAGGLE_NAME' does not exist!\"\n",
    "assert KAGGLE_NAME != '', f\"You forgot to enter your KAGGLE_NAME\"\n",
    "print(f'Kaggle Leaderboard Name: {KAGGLE_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 4: Model interpretations </b> </div>\n",
    "\n",
    "In this problem you will be building and interpreting models to predict whether or not a flight was delayed for its arrival based on features that could be measured as the flight takes off.  The included variables are:\n",
    "\n",
    "**ARRIVAL_DELAY**: the difference between scheduled arrival and actual arrival, in minutes (positive is late, negative is early).\n",
    "\n",
    "**DISTANCE**: the distance between arrival and departure airports, in miles.\n",
    "\n",
    "**SCHEDULED_TIME**: the amount of time the flight was scheduled to take.\n",
    "\n",
    "**MONTH**: the month the flight took off, 1 = January, 2 = February, etc.\n",
    "\n",
    "**SCHED_DEP_HOUR**: the scheduled departure time (the hour of the day).\n",
    "\n",
    "**SCHED_ARR_HOUR**: the scheduled arrival time (the hour of the day).\n",
    "\n",
    "**FLIGHT_COUNT**: the number of flights flying out of that airport before noon on a typical day.\n",
    "\n",
    "**DAY_OF_WEEK**: the day of the week, 1 = Monday, 2 = Tuesday, etc.\n",
    "\n",
    "**ORIGIN_AIRPORT**: the airport the flight took off from.\n",
    "\n",
    "**DESTINATION_AIRPORT**: the airport the flight was scheduled to land at.\n",
    "\n",
    "For the airport codes, see: https://www.bts.gov/topics/airlines-and-airports/world-airport-codes\n",
    "\n",
    "This problem steps you through fitting several models (starting simple, tuning a  and building up to complex), evaluate their accuracies, and then interpret the relationships of the predictors in the models via feature importance measures and through plotting their predications.\n",
    "\n",
    "*Note: the observations were stratified sampled so that roughly half of the observations were delayed and half of the observations were not delayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.1**  Read in the dataset `flights.csv`. Create a variable `DELAY_OR_NOT` that denotes whether `ARRIVAL_DELAY` is greater than or equal to 15 minutes (the FAA and BTS define a flight as delayed only if it arrives 15 minutes late or more). Turn the following predictors into dummies: `['ORIGIN_AIRPORT','DESTINATION_AIRPORT']`, and then split into train and test (80-20 split) using `train_test_split` with a random state of `109`.  Print out the dimensions of the resulting train and test `flights_train` and `flights_test` data frames.\n",
    "\n",
    "**4.2** Fit two tree based models: one with `max_depth = 20` (call it `tree20`) and one with a `best_depth` that is chosen via 5-fold cross-validation (call it `tree_best`) using all predictors.  Evaluate these two models via AUC on both train and test.  Print out `tree20_train_auc`, `tree20_test_auc`, `tree_best_train_auc`, and `tree_best_test_auc` (make sure they are well-labeled in the print out; see primer below).\n",
    "\n",
    "**4.3** Interpret your tree based models.  Provide a plot with the **relative** variable importance of the 10 most important predictors, `top_predictors` in each of the two models.  Interpret (i) which variables are clearly most important and (ii) compare to each other to describe how the two models differ and/or agree with which variables matter. \n",
    "\n",
    "**4.4** Fit an artifical neural network model (call it `NN_model`) using all predictors.  Use a dense 2-layer feed-forward network (1 input, 1 hidden) with 15 nodes in each layer.  Evaluate the model on both train and test, and print out the resulting `NN_model_train_auc`, `NN_model_train_auc`.\n",
    "\n",
    "**4.5** Fit a classification tree with `max_depth=20` on the predictions from your `NN_model`.  Call it `dec_tree_NN`.  Draw the first 3 layers of the tree and interpret what predictors seem most important in `dec_tree_NN` from the top of this tree.\n",
    "\n",
    "**4.6** Use your `dec_tree_NN` to measure **relative** variable importance in your `NN_model` and provide a plot for the 10 most important predictors.  How do these compare to those from 4.3 and the drawn tree in 4.5?  Discuss in 2-4 sentences.\n",
    "\n",
    "**4.7** Interpret the results of your `NN_model` via plotting predicted probabilities of delay vs. `SCHED_DEP_HOUR` when all the other variables are set to their means/modes.  Interpret what you see in 2-4 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.1**  Read in the dataset `flights.csv`. Create a variable `DELAY_OR_NOT` that denotes whether `ARRIVAL_DELAY` is greater than or equal to 15 minutes (the FAA and BTS define a flight as delayed only if it arrives 15 minutes late or more). Turn the following predictors into dummies: `['ORIGIN_AIRPORT','DESTINATION_AIRPORT']`, and then split into train and test (80-20 split) using `train_test_split` with a random state of `109`.  Print out the dimensions of the resulting train and test `flights_train` and `flights_test` data frames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "test": "test_4.1"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.1) ### \n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### 4.1 Check that you have the requested variables\n",
    "for var in ['flights_train', 'flights_test']:\n",
    "    assert var in globals(), f\"Variable '{var}' does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.2** Fit two tree based models: one with `max_depth = 20` (call it `tree20`) and one with a `best_depth` that is chosen via 5-fold cross-validation (call it `tree_best`) using all predictors.  Evaluate these two models via AUC on both train and test.  Print out `tree20_train_auc`, `tree20_test_auc`, `tree_best_train_auc`, and `tree_best_test_auc` (make sure they are well-labeled in the print out; see primer below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "deletable": false,
    "test": "test_4.2a"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.2a) ### \n",
    "# your code here\n",
    "# end of your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "test": "test_4.2b"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.2b) ### \n",
    "# Decision Tree Classifier\n",
    "# your code here \n",
    "# end of your code here\n",
    "### 4.2 Check that you have the requested variables\n",
    "for var in ['tree20', 'tree_best', 'best_depth']:\n",
    "    assert var in globals(), f\"Variable '{var}' does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "test": "test_4.2c"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.2c) ### \n",
    "# primer to print: \n",
    "# print(\"tree20_train_auc:\", roc_auc_score(y_train, y_hat))\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.3** Interpret your tree based models.  Provide a plot with the **relative** variable importance of the 10 most important predictors, `top_predictors` in each of the two models.  Interpret (i) which variables are clearly most important and (ii) compare to each other to describe how the two models differ and/or agree with which variables matter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "test": "test_4.3"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.3) ### \n",
    "#feature importance\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.4** Fit an artifical neural network model (call it `NN_model`) using all predictors.  Use a dense 2-layer feed-forward network (1 input, 1 hidden) with 15 nodes in each layer.  Evaluate the model on both train and test, and print out the resulting `NN_model_train_auc`, `NN_model_train_auc`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "test": "test_4.4"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.4) ### \n",
    "# build the NN \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### 4.4 Check that you have the requested variables\n",
    "for var in ['NN_model']:\n",
    "    assert var in globals(), f\"Variable '{var}' does not exist!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# compile it and run it\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# plot train and val acc as  a function of epochs\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "test": "test_4.4b"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.4b) ### \n",
    "# primer to print: \n",
    "# print(\"NN_model_train_auc:\", roc_auc_score(y_train, y_hat))\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.5",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.5** Fit a classification tree with `max_depth=20` on the predictions from your `NN_model`.  Call it `dec_tree_NN`.  Draw the first 3 layers of the tree and interpret what predictors seem most important in `dec_tree_NN` from the top of this tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>WARNING!:</b><span style = 'color:black'> Do not delete any of the `### cs109Test() ###` comment lines!</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "test": "test_4.5"
   },
   "outputs": [],
   "source": [
    "### cs109Test (test_4.5) ### \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</span></div><div class='alert alert-block alert-danger'><b>Note:</b><span style = 'color:black'> Make sure your submission passes all assert statements we've provided in this notebook.</span></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### 4.5 Check that you have the requested variables\n",
    "for var in ['dec_tree_NN']:\n",
    "    assert var in globals(), f\"Variable '{var}' does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.6",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.6** Use your `dec_tree_NN` to measure **relative** variable importance in your `NN_model` and provide a plot for the 10 most important predictors.  How do these compare to those from 4.3 and the drawn tree in 4.5?  Discuss in 2-4 sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "4.7",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**4.7** Interpret the results of your `NN_model` via plotting predicted probabilities of delay vs. `SCHED_DEP_HOUR` when all the other variables are set to their means/modes.  Interpret what you see in 2-4 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
